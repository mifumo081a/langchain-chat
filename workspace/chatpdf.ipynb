{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62485357-4704-44cb-9d97-dd79acc23775",
   "metadata": {},
   "source": [
    "- https://dev.classmethod.jp/articles/python-parse-pdf/\n",
    "- https://colab.research.google.com/github/nyanta012/demo/blob/main/sentence_retrieval.ipynb#scrollTo=_5bY_6TK_yFC\n",
    "- https://blog.langchain.dev/langchain-chat/\n",
    "- https://zenn.dev/umi_mori/books/prompt-engineer/viewer/langchain_indexes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a750521",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mifumo081a/langchain-chat/blob/main/workspace/chatpdf.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f7495c-2fac-4d03-aed2-4b3b48c2f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers sentencepiece sentence_transformers accelerate langchain openai chromadb\n",
    "# !pip install pymupdf python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6c7993-0671-4abc-8c4a-2d5f7d98cb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 20:02:23.678 INFO    matplotlib.font_manager: generated new fontManager\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import fitz\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "chatgpt_id = \"gpt-3.5-turbo\"\n",
    "en_list = [\n",
    "        \"bigscience/bloom-560m\",\n",
    "        \"bigscience/bloom-1b7\",\n",
    "        \"bigscience/bloomz-560m\",\n",
    "        \"bigscience/bloomz-1b7\",\n",
    "        # \"gpt2\",\n",
    "        \"gpt2-medium\",\n",
    "        \"gpt2-large\",\n",
    "        \"gpt2-xl\",\n",
    "        # \"facebook/opt-125m\",\n",
    "        \"facebook/opt-350m\",\n",
    "        \"facebook/opt-1.3b\",\n",
    "        # \"cerebras/Cerebras-GPT-111M\",\n",
    "        \"cerebras/Cerebras-GPT-256M\",\n",
    "        \"cerebras/Cerebras-GPT-590M\",\n",
    "        \"cerebras/Cerebras-GPT-1.3B\",\n",
    "        \"vicgalle/gpt2-alpaca\",\n",
    "]\n",
    "ja_list = [\n",
    "        # \"cyberagent/open-calm-small\",\n",
    "        \"cyberagent/open-calm-medium\",\n",
    "        \"cyberagent/open-calm-large\",\n",
    "        \"cyberagent/open-calm-1b\",\n",
    "        # \"rinna/japanese-gpt2-xsmall\",\n",
    "        # \"rinna/japanese-gpt2-small\",\n",
    "        \"rinna/japanese-gpt2-medium\",\n",
    "        # \"rinna/japanese-gpt-1b\",\n",
    "        \"rinna/japanese-gpt-neox-small\",\n",
    "        \"abeja/gpt2-large-japanese\",\n",
    "        # \"abeja/gpt-neox-japanese-2.7b\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_llm(model_id, model_kwargs, pipeline_kwargs):\n",
    "    if torch.cuda.is_available():\n",
    "        device = 0\n",
    "    else:\n",
    "        device = -1\n",
    "    if model_id == chatgpt_id:\n",
    "        load_dotenv()\n",
    "        llm = ChatOpenAI(model_name=chatgpt_id)\n",
    "    else:\n",
    "        llm = HuggingFacePipeline.from_model_id(\n",
    "            model_id, task=\"text-generation\",\n",
    "            model_kwargs=model_kwargs,\n",
    "            pipeline_kwargs=pipeline_kwargs,\n",
    "            device=device,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    return llm\n",
    "\n",
    "\n",
    "def get_embeddings(model_id):\n",
    "    if model_id == chatgpt_id:\n",
    "        return OpenAIEmbeddings()\n",
    "    # elif model_id in ja_list:\n",
    "    #     return HuggingFaceEmbeddings(model_name=\"oshizo/sbert-jsnli-luke-japanese-base-lite\")\n",
    "    else:\n",
    "        return HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eed7e73-0eb4-4f9f-b2b6-6d2e33842f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "475b3f22-320c-453a-9ca2-5e295a33cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "            \"min_length\": 20,\n",
    "            \"max_length\": 100,\n",
    "            \"repetition_penalty\": 1.01,\n",
    "            \"do_sample\": True,\n",
    "            \"top_p\": 0.95,\n",
    "            \"top_k\": 50,\n",
    "            \"temperature\": 0.1,\n",
    "        }\n",
    "pipeline_kwargs = {\n",
    "            \"min_new_tokens\": 5,\n",
    "            \"max_new_tokens\": 50,\n",
    "}\n",
    "\n",
    "model_id = \"bigscience/bloom-560m\"\n",
    "\n",
    "llm = get_llm(model_id, model_kwargs, pipeline_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8ec9c95-e5e0-4643-b8a2-de606cda4cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://buildmedia.readthedocs.org/media/pdf/pdfminer-docs/latest/pdfminer-docs.pdf\"\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4bc1765-4a6e-4bc1-9dba-a370d07b199a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 20:13:51.810 INFO    sentence_transformers.SentenceTransformer: Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2023-06-27 20:13:52.226 INFO    chromadb.db.duckdb: Exiting: Cleaning up .chroma directory\n",
      "2023-06-27 20:13:52.388 INFO    sentence_transformers.SentenceTransformer: Use pytorch device: cuda\n",
      "2023-06-27 20:13:52.389 INFO    chromadb.telemetry.posthog: Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f556d3ed28c64f0fb2272ad8104d6741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if res is not None:\n",
    "    doc = fitz.open(stream=res.content, filetype=\"pdf\")\n",
    "\n",
    "    docs = [\n",
    "                Document(\n",
    "                    page_content=page.get_text().encode(\"utf-8\"),\n",
    "                    metadata=dict(\n",
    "                        {\n",
    "                            \"page_number\": page.number + 1,\n",
    "                            \"total_pages\": len(doc),\n",
    "                        },\n",
    "                        **{\n",
    "                            k: doc.metadata[k]\n",
    "                            for k in doc.metadata\n",
    "                            if type(doc.metadata[k]) in [str, int]\n",
    "                        },\n",
    "                    ),\n",
    "                )\n",
    "                for page in doc\n",
    "            ]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(docs)\n",
    "    # print(texts)\n",
    "\n",
    "    embeddings = get_embeddings(model_id)\n",
    "    vectordb = Chroma.from_documents(texts, embeddings)\n",
    "\n",
    "    qa_chain = pdf_qa = ConversationalRetrievalChain.from_llm(llm, vectordb.as_retriever(), return_source_documents=True)\n",
    "else:\n",
    "    print(\"Exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea0e592-d169-457e-96cf-934b535288e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd724aa5bf5c4fbbaa878e2cc526264d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  What is PDFMiner?\n",
      "Answer:   The name comes from its title (“Pdf Miner”). This means that this program can be used for extracting text content in any kind of file format including.doc,.xlsx,.ppt,.txt etc., even if they’re not formatted\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35e2174c2f147f7a95efba5b079f4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/pipelines/base.py:1081: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Tell me some more details\n",
      "Answer:   http://stackoverflow.com/questions/41249172/how-to-use-pdf-miner-to-copy-a-document-from-an-external-file\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "text_input = \"What is PDFMiner?\"\n",
    "result = qa_chain({\"question\": text_input, \"chat_history\": chat_history})\n",
    "print(\"Input: \", text_input)\n",
    "print(\"Answer: \", result[\"answer\"])\n",
    "# print(\"Source: \", result[\"source_documents\"])\n",
    "chat_history.append((text_input, result[\"answer\"], result[\"source_documents\"]))\n",
    "text_input = \"Tell me some more details.\"\n",
    "result = qa_chain({\"question\": text_input, \"chat_history\": chat_history})\n",
    "print(\"Input: \", text_input)\n",
    "print(\"Answer: \", result[\"answer\"])\n",
    "# print(\"Source: \", result[\"source_documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1b228c5-d6d7-4a6a-b749-2f7ffc0eca07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tell me some details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b41fd3e52e644fa9752c986d623591a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  Tell me some details.\n",
      "Answer:   How do I get this program working?\n",
      "Answer 1: The main function is: \n",
      "pdfminer(filename)\n",
      "This will return all files from your computer (or any other file system) containing text or graphics.  You can use it either directly using.exe command\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-27 20:24:25.039 INFO    chromadb.db.duckdb: Exiting: Cleaning up .chroma directory\n",
      "2023-06-27 20:24:25.042 INFO    chromadb.db.duckdb: Exiting: Cleaning up .chroma directory\n",
      "2023-06-27 20:24:25.042 INFO    chromadb.db.duckdb: Exiting: Cleaning up .chroma directory\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "while True:\n",
    "    text_input = input()\n",
    "    if text_input == \"exit\":\n",
    "        break\n",
    "    result = qa_chain({\"question\": text_input, \"chat_history\": chat_history})\n",
    "    print(\"Input: \", text_input)\n",
    "    print(\"Answer: \", result[\"answer\"])\n",
    "    chat_history.append((text_input, result[\"answer\"], result[\"source_documents\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
